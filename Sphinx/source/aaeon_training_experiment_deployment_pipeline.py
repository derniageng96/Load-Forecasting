"""AAEON Training Experiment-Deployment-Pipeline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IXGV2XyTIVjpGynkYPMFJ8l1-sctIQkk

# Import Libray
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import mean_squared_error
from sklearn.utils import shuffle
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import plotly.graph_objects as go
import plotly.offline as py
import matplotlib.pyplot as plt
import math
import pickle
from keras.callbacks import EarlyStopping
from numpy import concatenate

"""# Define function 
## Helper consist of 2 function 

### 1. Mean Absolute Error 
To calculate loss from the models

### 2. generateDataset

To form a time series set 

## train_LSTM_Model

Construct the training and testing dataset and deep learning framework

"""

class Helper:
    """ 
    Helper contains 3 functions
    
    Attributes:
        mean_absolute_percentage_error (int) : a loss metric of load forecasting 
        generateDataSet (dataframe) : reframe the dataset into time series 
        train_LSTM_model (dataframe) : constructing load forecasting 
    """

    def mean_absolute_percentage_error(self,y_true, y_pred):
        """a loss metric function for load forecasting
        
        Parameters:
            y_true (int) : actual load value
            y_pred (int) : load prediction value
        
        Returns:
            mape (float) : MAPE of load forecasting
        """

        y_true, y_pred = np.array(y_true), np.array(y_pred)
        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    def generateDataSet(self, data, n_in=1, n_out=1, dropnan=True):
        """a function for creating time series dataframe
        
        Parameters:
            data (dataframe) : load data and additional features
            n_in (int, optional) : number of dataframe in (default 1)
            n_out (int, optional) : number of dataframe out (default 1)
            dropnan (boolean) : drop missing values (default True)

        Returns: 
            reframed (dataframe) : a transformed dataframe
        """

        n_vars = 1 if type(data) is list else data.shape[1]
        df = pd.DataFrame(data)
        cols, names = list(), list()
        # input sequence (t-n, ... t-1)
        for i in range(n_in, 0, -1):
            cols.append(df.shift(i))
            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]
        # forecast sequence (t, t+1, ... t+n)
        for i in range(0, n_out):
            cols.append(df.shift(-i))
            if i == 0:
                names += [('var%d(t)' % (j+1)) for j in range(n_vars)]
            else:
                names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]
        # put it all together
        agg = pd.concat(cols, axis=1)
        agg.columns = names
        # drop rows with NaN values
        if dropnan:
            agg.dropna(inplace=True)
        return agg

    def train_LSTM_model(self,reframed):
        """Define dataset for training and construct the model
        
        Parameters:
            reframed (dataframe) : a reframed dataset from generateDataSet funtion

        Returns:
            model (object) : best model after training
        """
        
        n_hours = 9
        n_features = 5
        values = reframed.values
        # Define number of training and testing set # 60 for two months 150 for 5 months
        n_train_hours = 24*150 
        train = values[:n_train_hours, :]
        test = values[n_train_hours:, :]
        # split into input and outputs
        n_obs = n_hours*n_features
        train_X, train_y = train[:, :n_obs], train[:, -n_features]
        test_X, test_y = test[:, :n_obs], test[:, -n_features]
        print(train_X.shape, len(train_X), train_y.shape)
        # reshape input to be 3D [samples, timesteps, features]
        train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))
        test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))
        print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)

        # design network
        model = keras.Sequential()
        model.add(layers.LSTM(50, activation='linear',input_shape=(train_X.shape[1], train_X.shape[2])))
        model.add(layers.Dense(50,activation='linear'))
        model.add(layers.Dense(1))
        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=50)
        model.compile(loss='mean_squared_error', optimizer='adam')
        # fit network
        history = model.fit(train_X, train_y, epochs=1000, batch_size=24, validation_data=(test_X[:1800], test_y[:1800]), verbose=2, shuffle=False, callbacks=[es])

        yhat = model.predict(test_X)
        test_X = test_X.reshape((test_X.shape[0], n_hours*n_features))
        inv_yhat = concatenate((yhat, test_X[:, -4:]), axis=1)                        
        inv_yhat = inv_yhat[:,0]
        test_y = test_y.reshape((len(test_y), 1))
        inv_y = concatenate((test_y, test_X[:, -4:]), axis=1)
        inv_y = inv_y[:,0]
        # calculate RMSE of inversed value 
        rmse = math.sqrt(mean_squared_error(inv_y, inv_yhat))
        print('Test RMSE: %.3f' % rmse) 

        pct = self.mean_absolute_percentage_error(inv_y,inv_yhat)
        print('MAPE : %.3f' % pct +'%' )

        return model

"""# Load Dataset and use the function for load forecasting"""

def main():
    pw=pd.read_csv('changyuanbuilding_interpolation_SGF_202007-202104.csv')

    dataset = pd.DataFrame()
    dataset = pw[['p_sum','ae_tot','weekend','Temperature','session']]
    # dataset = pw[['p_sum','ae_tot','weekend','Temp(Â¢J)','session']]
    print(dataset.head())

    helper = Helper()
    reframed = helper.generateDataSet(dataset, 9, 1)
    model = helper.train_LSTM_model(reframed)
    model.save("model")

if __name__ == '__main__':
    main()
